maintainer       "Chris Howe - Infochimps, Inc"
maintainer_email "coders@infochimps.com"
license          "Apache 2.0"
long_description IO.read(File.join(File.dirname(__FILE__), 'README.md'))
version          "3.0.3"

description      "Flume: reliable decoupled shipment of logs and data."

depends          "java"
depends          "apt"
depends          "runit"

depends          "volumes"
depends          "metachef"

recipe           "flume::default",                     "Base configuration for flume"
recipe           "flume::hbase_sink_plugin",           "Hbase Sink Plugin"
recipe           "flume::jruby_plugin",                "Jruby Plugin"
recipe           "flume::master",                      "Configures Flume Master, installs and starts service"
recipe           "flume::node",                        "Configures Flume Node, installs and starts service"
recipe           "flume::test_flow",                   "Test Flow"
recipe           "flume::add_cloudera_repo",           "Add Cloudera repo to package manager"

%w[ debian ubuntu ].each do |os|
  supports os
end

attribute "apt/cloudera/force_distro",
  :display_name          => "Override the distro name apt uses to look up repos",
  :description           => "Typically, leave this blank. However if (as is the case in Nov 2011) you are on natty but Cloudera's repo only has packages up to maverick, use this to override.",
  :default               => ""

attribute "apt/cloudera/release_name",
  :display_name          => "Release identifier (eg cdh3u2) of the cloudera repo to use. See also hadoop/deb_version",
  :description           => "Release identifier (eg cdh3u2) of the cloudera repo to use. See also hadoop/deb_version",
  :default               => "cdh3u2"

attribute "flume/aws_access_key",
  :display_name          => "AWS access key used for writing to s3 buckets",
  :description           => "AWS access key used for writing to s3 buckets",
  :default               => ""

attribute "flume/aws_secret_key",
  :display_name          => "AWS secret key used for writing to s3 buckets",
  :description           => "AWS secret key used for writing to s3 buckets",
  :default               => ""

attribute "flume/cluster_name",
  :display_name          => "",
  :description           => "The name of the cluster to participate with (masters and zookeepers...)",
  :default               => "cluster_name"

attribute "flume/plugins",
  :display_name          => "Hash for plugin configuration",
  :description           => "If you have a particular plugin to configure, you can also configure the classpath and the classes to include in the configuration file with attributes in the following forms:\nnode[:flume][:plugin][{plugin_name}][:classes]\nnode[:flume][:plugin][{plugin_name}][:classpath]\nnode[:flume][:plugin][{plugin_name}][:java_opts]",
  :default               => ""

attribute "flume/classes",
  :display_name          => "",
  :description           => "",
  :default               => ""

attribute "flume/classpath",
  :display_name          => "list of directories and jars to add to the FLUME_CLASSPATH",
  :description           => "list of directories and jars to add to the FLUME_CLASSPATH",
  :default               => ""

attribute "flume/java_opts",
  :display_name          => "list of command line parameters to add to the jvm",
  :description           => "list of command line parameters to add to the jvm",
  :default               => ""

attribute "flume/collector",
  :display_name          => "Format of node's logs",
  :description           => "output_format -- Controls what format the node writes logs (using collectorSink):\n * avro - Avro Native file format. Default currently is uncompressed.\n * avrodata - Binary encoded data written in the avro binary format.\n * avrojson - JSON encoded data generated by avro.\n * default - a debugging format.\n * json - JSON encoded data.\n * log4j - a log4j pattern similar to that used by CDH output pattern.\n * raw - Event body only. This is most similar to copying a file but does not preserve any uniqifying metadata like host/timestamp/nanos.\n * syslog - a syslog like text output format.\n\ncodec -- Controls what kind of compression the collector will use when writing a file.\nwhether or not collected logs are gzipped before writing\nthem to their final resting place (using collectorSink)\n * GZipCodec\n * BZip2Codec\n",
  :default               => ""

attribute "flume/data_dir",
  :display_name          => "Directory for local in-transit files",
  :description           => "Directory for local in-transit files",
  :default               => "/data/db/flume"

attribute "flume/home_dir",
  :display_name          => "",
  :description           => "",
  :default               => "/usr/lib/flume"

attribute "flume/conf_dir",
  :display_name          => "",
  :description           => "",
  :default               => "/etc/flume/conf"

attribute "flume/log_dir",
  :display_name          => "",
  :description           => "",
  :default               => "/var/log/flume"

attribute "flume/pid_dir",
  :display_name          => "",
  :description           => "",
  :default               => "/var/run/flume"

attribute "flume/master/external_zookeeper",
  :display_name          => "Use External Zookeeper?",
  :description           => "false to use flume's zookeeper. True to attach to an external zookeeper.",
  :default               => ""

attribute "flume/master/zookeeper_port",
  :display_name          => "port to talk to zookeeper on (for external zookeeper)",
  :description           => "port to talk to zookeeper on (for external zookeeper)",
  :default               => "2181"

attribute "flume/master/run_state",
  :display_name          => "",
  :description           => "",
  :default               => "stop"

attribute "flume/node/run_state",
  :display_name          => "",
  :description           => "",
  :default               => "stop"
